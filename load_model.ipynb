{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n",
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_model():\n",
    "    print(\"Loading the model...\")\n",
    "    global model\n",
    "    model = tf.keras.models.load_model(\"models/handwash_model_v1.2.keras\")\n",
    "    # model = tf.keras.models.load_model(\"models/downloaded_model.keras\")\n",
    "    print(\"model loaded successfully!\")\n",
    "\n",
    "load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(vid_pth):\n",
    "    vidcap = cv2.VideoCapture(vid_pth)\n",
    "\n",
    "    is_success, image = vidcap.read()\n",
    "    frame_number = 0\n",
    "\n",
    "    freq_dict = dict()\n",
    "\n",
    "    while is_success:\n",
    "        if frame_number%20 == 0:\n",
    "            img = image[..., ::-1] / 255.\n",
    "            img = np.expand_dims(cv2.resize(img, (256, 256)), axis=0)\n",
    "            probas = model.predict(img, verbose=0)\n",
    "            pred = probas.argmax()\n",
    "            if pred in freq_dict:\n",
    "                freq_dict[pred] += 1\n",
    "            else:\n",
    "                freq_dict[pred] = 1\n",
    "        is_success, image = vidcap.read()\n",
    "        frame_number += 1\n",
    "\n",
    "    labels_dict = {0: \"Rub both wrists in rotating manner\",\n",
    "                1: \"Rub your palms together\",\n",
    "                2: \"Rub the back of your fingers and hands\",\n",
    "                3: \"Rub your hands by interlocking your fingers\",\n",
    "                4: \"Interlock fingers and rub the back of fingers of both hands\",\n",
    "                5: \"Rub the area between index finger and thumb\",\n",
    "                6: \"Rub fingertips on palm of both hands in circular manner\"}\n",
    "\n",
    "    max_freq_label = max(freq_dict.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "    # return f\"{labels_dict[max_freq_label]}\"\n",
    "    return f\"{max_freq_label}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"dataset/videos/test/0/HandWash_002_A_12_G_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_preds = []\n",
    "test_videos_dir = \"/home/vikas/Projects/freelancing/research/dataset/videos/test\"\n",
    "for folder in os.listdir(test_videos_dir):\n",
    "    for file in os.listdir(f\"{test_videos_dir}/{folder}\"):\n",
    "        if folder != predict(f\"{test_videos_dir}/{folder}/{file}\"):\n",
    "            incorrect_preds.append(f\"{test_videos_dir}/{folder}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_videos = 0\n",
    "test_videos_dir = \"/home/vikas/Projects/freelancing/research/dataset/videos/test\"\n",
    "for folder in os.listdir(test_videos_dir):\n",
    "    total_test_videos += len(os.listdir(f\"{test_videos_dir}/{folder}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_test_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_preds_dict = {}\n",
    "for path in incorrect_preds:\n",
    "    incorrect_label = path.split(\"/\")[-2]\n",
    "    if incorrect_label in incorrect_preds_dict:\n",
    "        incorrect_preds_dict[incorrect_label].append(path)\n",
    "    else:\n",
    "        incorrect_preds_dict[incorrect_label] = [path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vikas/Projects/freelancing/research/dataset/videos/test/0/HandWash_015_A_12_G_04.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/0/HandWash_018_A_11_G_05.mp4']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_preds_dict[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vikas/Projects/freelancing/research/dataset/videos/test/4/HandWash_019_A_05_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/4/HandWash_018_A_06_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/4/HandWash_019_A_06_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/4/HandWash_020_A_06_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/4/HandWash_020_A_05_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/0/HandWash_015_A_12_G_04.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/0/HandWash_018_A_11_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/3/HandWash_024_A_04_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/3/HandWash_021_A_04_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/5/HandWash_024_A_07_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/5/HandWash_025_A_07_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/5/HandWash_021_A_07_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_007_A_09_G_01.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_021_A_10_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_006_A_09_G_01.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_008_A_09_G_01.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_018_A_09_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/2/HandWash_018_A_03_G_05.mp4']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_preds_dict[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_007_A_09_G_01.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_021_A_10_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_006_A_09_G_01.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_008_A_09_G_01.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/6/HandWash_018_A_09_G_05.mp4']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_preds_dict[\"6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0: \"Rub both wrists in rotating manner\",\n",
    "            1: \"Rub your palms together\",\n",
    "            2: \"Rub the back of your fingers and hands\",\n",
    "            3: \"Rub your hands by interlocking your fingers\",\n",
    "            4: \"Interlock fingers and rub the back of fingers of both hands\",\n",
    "            5: \"Rub the area between index finger and thumb\",\n",
    "            6: \"Rub fingertips on palm of both hands in circular manner\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rub fingertips on palm of both hands in circular manner'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 4 has 5 incorrect predictions\n",
      "label 0 has 2 incorrect predictions\n",
      "label 3 has 2 incorrect predictions\n",
      "label 5 has 3 incorrect predictions\n",
      "label 6 has 5 incorrect predictions\n",
      "label 2 has 1 incorrect predictions\n"
     ]
    }
   ],
   "source": [
    "for k, v in incorrect_preds_dict.items():\n",
    "    print(f\"label {k} has {len(v)} incorrect predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(vid_pth):\n",
    "    vidcap = cv2.VideoCapture(vid_pth)\n",
    "\n",
    "    is_success, image = vidcap.read()\n",
    "    frame_number = 0\n",
    "\n",
    "    freq_dict = dict()\n",
    "\n",
    "    probas_array = []\n",
    "\n",
    "    while is_success:\n",
    "        if frame_number%20 == 0:\n",
    "            img = image[..., ::-1] / 255.\n",
    "            img = np.expand_dims(cv2.resize(img, (256, 256)), axis=0)\n",
    "            probas = model.predict(img, verbose=0)\n",
    "            probas_array.append(probas)\n",
    "            pred = probas.argmax()\n",
    "            if pred in freq_dict:\n",
    "                freq_dict[pred] += 1\n",
    "            else:\n",
    "                freq_dict[pred] = 1\n",
    "        is_success, image = vidcap.read()\n",
    "        frame_number += 1\n",
    "\n",
    "    probas_array = np.array(probas_array)\n",
    "\n",
    "    labels_dict = {0: \"Rub both wrists in rotating manner\",\n",
    "                1: \"Rub your palms together\",\n",
    "                2: \"Rub the back of your fingers and hands\",\n",
    "                3: \"Rub your hands by interlocking your fingers\",\n",
    "                4: \"Interlock fingers and rub the back of fingers of both hands\",\n",
    "                5: \"Rub the area between index finger and thumb\",\n",
    "                6: \"Rub fingertips on palm of both hands in circular manner\"}\n",
    "\n",
    "    # max_freq_label = max(freq_dict.items(), key=lambda x: x[1])[0]\n",
    "    max_mean_proba_label = probas_array.mean(axis=0).argmax()\n",
    "\n",
    "    # return f\"{labels_dict[max_freq_label]}\"\n",
    "    return f\"{max_mean_proba_label}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_preds2 = []\n",
    "test_videos_dir = \"/home/vikas/Projects/freelancing/research/dataset/videos/test\"\n",
    "for folder in os.listdir(test_videos_dir):\n",
    "    for file in os.listdir(f\"{test_videos_dir}/{folder}\"):\n",
    "        if folder != predict2(f\"{test_videos_dir}/{folder}/{file}\"):\n",
    "            incorrect_preds2.append(f\"{test_videos_dir}/{folder}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_preds_dict2 = {}\n",
    "for path in incorrect_preds2:\n",
    "    incorrect_label = path.split(\"/\")[-2]\n",
    "    if incorrect_label in incorrect_preds_dict2:\n",
    "        incorrect_preds_dict2[incorrect_label].append(path)\n",
    "    else:\n",
    "        incorrect_preds_dict2[incorrect_label] = [path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vikas/Projects/freelancing/research/dataset/videos/test/0/HandWash_019_A_11_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/0/HandWash_015_A_12_G_04.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/0/HandWash_020_A_11_G_05.mp4',\n",
       " '/home/vikas/Projects/freelancing/research/dataset/videos/test/0/HandWash_018_A_11_G_05.mp4']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_preds_dict2[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'incorrect_preds_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mincorrect_preds_dict\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'incorrect_preds_dict' is not defined"
     ]
    }
   ],
   "source": [
    "incorrect_preds_dict[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_videos2(test_videos_path):\n",
    "    num_total_videos = 0\n",
    "    num_correctly_predicted = 0\n",
    "    for folder in os.listdir(test_videos_path):\n",
    "        for file in os.listdir(f\"{test_videos_path}/{folder}\"):\n",
    "            if folder == predict2(f\"{test_videos_path}/{folder}/{file}\"):\n",
    "                num_correctly_predicted += 1\n",
    "            num_total_videos += 1\n",
    "        print(f\"{folder=} processed successfully!\")\n",
    "\n",
    "    return num_correctly_predicted/num_total_videos*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder='4' processed successfully!\n",
      "folder='1' processed successfully!\n",
      "folder='0' processed successfully!\n",
      "folder='3' processed successfully!\n",
      "folder='5' processed successfully!\n",
      "folder='6' processed successfully!\n",
      "folder='2' processed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.17073170731707"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_videos2(\"dataset/videos/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_videos(test_videos_path):\n",
    "    num_total_videos = 0\n",
    "    num_correctly_predicted = 0\n",
    "    for folder in os.listdir(test_videos_path):\n",
    "        for file in os.listdir(f\"{test_videos_path}/{folder}\"):\n",
    "            if folder == predict(f\"{test_videos_path}/{folder}/{file}\"):\n",
    "                num_correctly_predicted += 1\n",
    "            num_total_videos += 1\n",
    "        print(f\"{folder=} processed successfully!\")\n",
    "\n",
    "    return num_correctly_predicted/num_total_videos*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder='4' processed successfully!\n",
      "folder='1' processed successfully!\n",
      "folder='0' processed successfully!\n",
      "folder='3' processed successfully!\n",
      "folder='5' processed successfully!\n",
      "folder='6' processed successfully!\n",
      "folder='2' processed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.60975609756098"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_videos(\"dataset/videos/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for folder in os.listdir(\"dataset/videos/test\"):\n",
    "    cnt += len(os.listdir(f\"dataset/videos/test/{folder}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.8"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "82*90/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.2439024390244"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "74/82*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "82-74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
